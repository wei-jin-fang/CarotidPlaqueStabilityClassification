# Patch-based é¢ˆåŠ¨è„‰æ–‘å—åˆ†ç±»ç³»ç»Ÿ

## ç³»ç»Ÿæ¦‚è¿°

æœ¬ç³»ç»Ÿé‡‡ç”¨Patch-basedæ–¹æ³•è§£å†³å°ROIåŒºåŸŸçš„èƒŒæ™¯å¹²æ‰°é—®é¢˜ï¼š

1. **Patchæå–**ï¼šä»maskçš„ç™½è‰²åŒºåŸŸå†…æå–å°patchï¼ˆ24Ã—24ï¼‰ï¼Œé¿å…é»‘è‰²èƒŒæ™¯
2. **Attentionèšåˆ**ï¼šé€šè¿‡attentionæœºåˆ¶å­¦ä¹ å“ªäº›patchæ›´é‡è¦
3. **ä½ç½®è®°å½•**ï¼šä¿å­˜æ¯ä¸ªpatchçš„ä½ç½®ä¿¡æ¯ï¼Œæ”¯æŒå¯è§†åŒ–
4. **çƒ­åŠ›å›¾å¯è§†åŒ–**ï¼šå°†patchçš„attentionæƒé‡æ˜ å°„å›åŸå›¾

## æ–‡ä»¶ç»“æ„

```
æ–°å¢æ–‡ä»¶ï¼š
â”œâ”€â”€ utils/dataset_patch_based.py      # Patchæ•°æ®é›†ç±»
â”œâ”€â”€ models/patch_classifier.py        # Patchåˆ†ç±»å™¨ï¼ˆå«Attentionï¼‰
â”œâ”€â”€ train_patch_based.py              # è®­ç»ƒè„šæœ¬
â”œâ”€â”€ train_patch_based.sh              # è®­ç»ƒShellè„šæœ¬
â””â”€â”€ visualize_patch_attention.py      # Attentionå¯è§†åŒ–è„šæœ¬
```

## æ ¸å¿ƒè®¾è®¡

### 1. Patchæå–ç­–ç•¥

```python
# ä»ä¸¤ä¸ªROIåŒºåŸŸåˆ†åˆ«æå–patch
- è¯†åˆ«maskä¸­çš„ç‹¬ç«‹åŒºåŸŸï¼ˆå·¦å³æ–‘å—ï¼‰
- æ¯ä¸ªROIå†…æ»‘çª—é‡‡æ ·ï¼ˆ50%é‡å ï¼‰
- æŒ‰maskè¦†ç›–ç‡è¿‡æ»¤ï¼ˆ>=30%æ˜¯å‰æ™¯ï¼‰
- è®°å½•æ¯ä¸ªpatchçš„ä½ç½®ä¿¡æ¯
```

**ç¤ºä¾‹**ï¼š
- Patchå¤§å°ï¼š24Ã—24åƒç´ 
- æ¯ä¸ªROIæå–ï¼š12ä¸ªpatch
- å‡è®¾2ä¸ªROIï¼Œ100ä¸ªslice â†’ çº¦2400ä¸ªpatch/æ ·æœ¬

### 2. æ¨¡å‹æ¶æ„

```
è¾“å…¥: [B, N_patches, 1, 24, 24]
  â†“
PatchEncoder (å…±äº«æƒé‡çš„2D CNN)
  â†“
Features: [B, N_patches, 128]
  â†“
AttentionAggregator
  â†“
Aggregated: [B, 128]  +  Attention Weights: [B, N_patches]
  â†“
Classifier
  â†“
è¾“å‡º: Logits [B, 2]
```

**å…³é”®**ï¼šAttentionæƒé‡ç”¨äºå¯è§†åŒ–patché‡è¦æ€§

### 3. ä½ç½®è®°å½•æœºåˆ¶

æ¯ä¸ªpatchè®°å½•ï¼š
```python
{
    'center_x': 60,        # patchä¸­å¿ƒxåæ ‡
    'center_y': 110,       # patchä¸­å¿ƒyåæ ‡
    'bbox': (48,98,72,122), # patchçš„çŸ©å½¢æ¡†
    'roi_id': 0,           # æ¥è‡ªå“ªä¸ªROIï¼ˆ0=å·¦ï¼Œ1=å³ï¼‰
    'slice_idx': 25,       # æ¥è‡ªç¬¬å‡ ä¸ªslice
    'mask_ratio': 0.85     # maskè¦†ç›–ç‡
}
```

## ä½¿ç”¨æ–¹æ³•

### æ­¥éª¤1ï¼šè®­ç»ƒæ¨¡å‹

```bash
# ç›´æ¥è¿è¡Œè®­ç»ƒè„šæœ¬
bash train_patch_based.sh

# æˆ–æ‰‹åŠ¨è°ƒæ•´å‚æ•°
python train_patch_based.py \
    --patch-size 24 \
    --max-patches-per-roi 12 \
    --overlap-ratio 0.5 \
    --epochs 50 \
    --batch-size 4 \
    --lr 1e-3
```

**è®­ç»ƒè¾“å‡º**ï¼š
```
output_patch_based/train_patch_YYYYMMDD_HHMMSS/
â”œâ”€â”€ models/
â”‚   â””â”€â”€ best_model.pth                        # æœ€ä½³æ¨¡å‹
â”œâ”€â”€ logs/
â”‚   â”œâ”€â”€ config.json                           # è®­ç»ƒé…ç½®
â”‚   â”œâ”€â”€ training_history.csv                  # è®­ç»ƒå†å²
â”‚   â”œâ”€â”€ training_curves.png                   # è®­ç»ƒæ›²çº¿
â”‚   â”œâ”€â”€ train_samples.csv                     # è®­ç»ƒé›†æ ·æœ¬
â”‚   â”œâ”€â”€ val_samples.csv                       # éªŒè¯é›†æ ·æœ¬
â”‚   â””â”€â”€ test_samples.csv                      # æµ‹è¯•é›†æ ·æœ¬
â””â”€â”€ results/
    â”œâ”€â”€ test_results.json                     # æµ‹è¯•é›†æŒ‡æ ‡
    â”œâ”€â”€ test_predictions_detailed.csv         # é¢„æµ‹ç»“æœCSV
    â””â”€â”€ test_predictions_with_attention.pkl   # è¯¦ç»†ç»“æœï¼ˆå«attentionï¼‰
```

### æ­¥éª¤2ï¼šå¯è§†åŒ–Patch Attention

```bash
# å¯è§†åŒ–æ‰€æœ‰æµ‹è¯•æ ·æœ¬
python visualize_patch_attention.py \
    --results-file output_patch_based/train_patch_YYYYMMDD_HHMMSS/results/test_predictions_with_attention.pkl \
    --output-dir ./visualizations_patch_attention

# åªå¯è§†åŒ–é”™è¯¯é¢„æµ‹
python visualize_patch_attention.py \
    --results-file output_patch_based/.../test_predictions_with_attention.pkl \
    --output-dir ./visualizations_errors \
    --only-errors

# é™åˆ¶æ•°é‡ + ç»Ÿè®¡åˆ†æ
python visualize_patch_attention.py \
    --results-file output_patch_based/.../test_predictions_with_attention.pkl \
    --output-dir ./visualizations_top20 \
    --max-samples 20 \
    --analyze-stats
```

**å¯è§†åŒ–è¾“å‡º**ï¼š
- æ¯ä¸ªæ ·æœ¬ç”Ÿæˆ4å¼ å›¾ï¼šåŸå›¾ã€Maskã€çƒ­åŠ›å›¾ã€å åŠ å›¾
- æ ‡æ³¨Top-5é‡è¦çš„patchï¼ˆç»¿è‰²æ¡†=æœ€é‡è¦ï¼‰
- æ˜¾ç¤ºé¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦

### æ­¥éª¤3ï¼šè§£è¯»å¯è§†åŒ–ç»“æœ

**çƒ­åŠ›å›¾å«ä¹‰**ï¼š
- ğŸ”´ çº¢è‰²åŒºåŸŸï¼šé«˜attentionæƒé‡ï¼Œæ¨¡å‹è®¤ä¸ºé‡è¦
- ğŸ”µ è“è‰²åŒºåŸŸï¼šä½attentionæƒé‡ï¼Œæ¨¡å‹ä¸å…³æ³¨
- ğŸŸ¢ ç»¿è‰²æ¡†ï¼šæœ€é‡è¦çš„patchï¼ˆTop-1ï¼‰
- ğŸŸ¡ é»„è‰²æ¡†ï¼šæ¬¡é‡è¦çš„patchï¼ˆTop 2-5ï¼‰

**åˆ†æç¤ºä¾‹**ï¼š
```
æ­£ç¡®é¢„æµ‹ï¼š
- çƒ­åŠ›å›¾é›†ä¸­åœ¨ROIä¸­å¿ƒåŒºåŸŸ
- Top-3 patchçš„attentionæƒé‡è¾ƒé«˜ï¼ˆ>0.15ï¼‰
- ä¸¤ä¸ªROIçš„attentionæƒé‡æœ‰æ˜æ˜¾å·®å¼‚

é”™è¯¯é¢„æµ‹ï¼š
- çƒ­åŠ›å›¾åˆ†æ•£ï¼Œæƒé‡åˆ†å¸ƒå‡åŒ€
- Top-3 patchæƒé‡è¾ƒä½ï¼ˆ<0.10ï¼‰
- å¯èƒ½å…³æ³¨äº†è¾¹ç¼˜æˆ–èƒŒæ™¯patch
```

## å‚æ•°è°ƒä¼˜æŒ‡å—

### Patchç›¸å…³å‚æ•°

```bash
--patch-size 24              # Patchå¤§å°
                             # å°ROIå»ºè®®: 16-24
                             # å¤§ROIå»ºè®®: 32-48

--max-patches-per-roi 12     # æ¯ä¸ªROIæœ€å¤šæå–çš„patchæ•°
                             # å½±å“ï¼šæ•°é‡å¤šâ†’ä¿¡æ¯ä¸°å¯Œä½†è®¡ç®—æ…¢
                             # å»ºè®®ï¼š8-16

--overlap-ratio 0.5          # Patché‡å æ¯”ä¾‹
                             # 0.5 = 50%é‡å ï¼Œå¯†é›†é‡‡æ ·
                             # 0.3 = 30%é‡å ï¼Œç¨€ç–é‡‡æ ·
```

### æ¨¡å‹å‚æ•°

```bash
--feature-dim 128            # ç‰¹å¾ç»´åº¦
                             # å½±å“æ¨¡å‹å®¹é‡ï¼Œå»ºè®®64-256

--batch-size 4               # æ‰¹æ¬¡å¤§å°
                             # patchå¤šæ—¶æ˜¾å­˜å ç”¨å¤§ï¼Œé…Œæƒ…è°ƒæ•´

--lr 1e-3                    # å­¦ä¹ ç‡
                             # ä»å¤´è®­ç»ƒå»ºè®®1e-3
```

## ä¸åŸæ–¹æ³•å¯¹æ¯”

| ç‰¹æ€§ | åŸæ–¹æ³•ï¼ˆè‡ªé€‚åº”è£å‰ªï¼‰ | Patch-basedæ–¹æ³• |
|------|---------------------|-----------------|
| èƒŒæ™¯å¤„ç† | é»‘è‰²padding | å®Œå…¨é¿å…èƒŒæ™¯ |
| ç©ºé—´ä¿¡æ¯ | ä¿ç•™å®Œæ•´ç»“æ„ | æ‰“æ•£ä¸ºpatch |
| å¯è§†åŒ– | æ”¯æŒGradCAM | Patch-levelçƒ­åŠ›å›¾ |
| ä¿¡æ¯å¯†åº¦ | ä½ï¼ˆæœ‰èƒŒæ™¯ï¼‰ | é«˜ï¼ˆ100%å‰æ™¯ï¼‰ |
| è®¡ç®—å¤æ‚åº¦ | ä½ | ä¸­ç­‰ |
| é€‚ç”¨åœºæ™¯ | ROIè¾ƒå¤§ | ROIå¾ˆå° |

## å¸¸è§é—®é¢˜

### Q1: Patchæ•°é‡ä¸ä¸€è‡´æ€ä¹ˆåŠï¼Ÿ
A: æ•°æ®åŠ è½½æ—¶ä¼šè‡ªåŠ¨paddingåˆ°ç›¸åŒé•¿åº¦ï¼Œè®­ç»ƒæ—¶ä½¿ç”¨maskæ ‡è®°æœ‰æ•ˆpatchã€‚

### Q2: ä¸¤ä¸ªROIå¤§å°å·®å¼‚å¤§ï¼Ÿ
A: Patchæå–å™¨ä¼šè‡ªåŠ¨å¤„ç†ï¼Œå°ROIæå–å°‘é‡patchï¼Œå¤§ROIæå–æ›´å¤šã€‚

### Q3: å¯è§†åŒ–ç»“æœçœ‹ä¸æ¸…ï¼Ÿ
A: å¯ä»¥è°ƒæ•´`top_k`å‚æ•°ï¼Œåªæ ‡æ³¨æœ€é‡è¦çš„å‡ ä¸ªpatchã€‚

### Q4: Attentionæƒé‡éƒ½å¾ˆå‡åŒ€ï¼Ÿ
A: å¯èƒ½æ˜¯æ¨¡å‹æ²¡æœ‰å­¦åˆ°åˆ¤åˆ«æ€§ç‰¹å¾ï¼Œå°è¯•ï¼š
- å¢åŠ è®­ç»ƒè½®æ•°
- è°ƒæ•´å­¦ä¹ ç‡
- å¢åŠ ç‰¹å¾ç»´åº¦

## æŠ€æœ¯ç»†èŠ‚

### Patchè¿‡æ»¤ç­–ç•¥

```python
# è¾¹ç•Œpatchå¤„ç†
mask_ratio = (patchå†…ç™½è‰²åƒç´ ) / (patchæ€»åƒç´ )

if mask_ratio >= 0.3:  # è‡³å°‘30%æ˜¯ROI
    ä¿ç•™patch
else:
    ä¸¢å¼ƒï¼ˆå¤ªå¤šèƒŒæ™¯ï¼‰
```

### Attentionæœºåˆ¶

```python
# Attention network
attention_logits = MLP(patch_features)  # [B, N, 1]
attention_weights = Softmax(attention_logits)  # [B, N]
aggregated_feature = Sum(attention_weights * patch_features)  # [B, D]
```

### çƒ­åŠ›å›¾ç”Ÿæˆ

```python
# å°†patchæƒé‡æ˜ å°„å›åŸå›¾
for each patch:
    heatmap[patch_bbox] += attention_weight

# é‡å åŒºåŸŸå–å¹³å‡
heatmap = heatmap / count_map
```

## åç»­æ”¹è¿›æ–¹å‘

1. **å¤šå°ºåº¦patch**ï¼šåŒæ—¶ä½¿ç”¨16Ã—16ã€24Ã—24ã€32Ã—32
2. **Patché€‰æ‹©ç­–ç•¥**ï¼šè®­ç»ƒæ—¶åŠ¨æ€é€‰æ‹©é‡è¦patch
3. **3D Attention**ï¼šæ²¿æ·±åº¦æ–¹å‘å»ºæ¨¡patchå…³ç³»
4. **å¯¹æ¯”å­¦ä¹ **ï¼šå­¦ä¹ åŒä¸€ROIå†…patchçš„ç›¸ä¼¼æ€§

## å¼•ç”¨

å¦‚æœæœ¬ä»£ç å¯¹æ‚¨çš„ç ”ç©¶æœ‰å¸®åŠ©ï¼Œè¯·å¼•ç”¨æˆ‘ä»¬çš„å·¥ä½œã€‚

---

**åˆ›å»ºæ—¶é—´**: 2025-12-26
**ä½œè€…**: Claude Code Assistant
